{
    "abstract": "In this paper, we propose a method that is able to derive rules involving range associations from numerical attributes, and to use such rules to build comprehensible classification and characterization (data summary) models. Our approach follows the classification association rule mining paradigm, where rules are generated in a way similar to association rule mining, but search is guided by rule consequents. This allows many credible rules, not just some dominant rules, to be mined from the data to build models. In so doing, we propose several sub-range analysis and rule formation heuristics to deal with numerical attributes. Our experiments show that our method is able to derive range-based rules that offer both accurate classification and comprehensible characterization for numerical data.",
    "bib_entries": {
        "b1": null,
        "b10": null,
        "b11": {
            "authors": [
                {
                    "first": "Salvador",
                    "initial": "S.",
                    "last": "Garc\u00eda"
                },
                {
                    "first": "Juli\u00e1n",
                    "initial": "J.",
                    "last": "Luengo"
                },
                {
                    "first": "Jos\u00e9 Antonio",
                    "initial": "J.A.",
                    "last": "S\u00e1ez"
                },
                {
                    "first": "Victoria",
                    "initial": "V.",
                    "last": "L\u00f3pez"
                },
                {
                    "first": "Francisco",
                    "initial": "F.",
                    "last": "Herrera"
                }
            ],
            "doi": "10.1109/TKDE.2012.35",
            "firstpage": "734",
            "issn": "10414347",
            "lastpage": "750",
            "pub_year": 2013,
            "title": "A survey of discretization techniques: Taxonomy and empirical analysis in supervised learning",
            "volume": "25"
        },
        "b12": null,
        "b13": {
            "authors": [
                {
                    "first": "Wang",
                    "initial": "W.",
                    "last": "Lian"
                },
                {
                    "first": "David W.",
                    "initial": "D.W.",
                    "last": "Cheung"
                },
                {
                    "first": "S. M.",
                    "initial": "S.M.",
                    "last": "Yiu"
                }
            ],
            "doi": "10.1016/j.camwa.2005.03.009",
            "firstpage": "471",
            "issn": "08981221",
            "lastpage": "490",
            "pub_year": 2005,
            "title": "An efficient algorithm for finding dense regions for mining quantitative association rules",
            "volume": "50"
        },
        "b14": {
            "authors": [
                {
                    "first": "J.",
                    "initial": "J.",
                    "last": "Mata"
                },
                {
                    "first": "J. L.",
                    "initial": "J.L.",
                    "last": "Alvarez"
                },
                {
                    "first": "J. C.",
                    "initial": "J.C.",
                    "last": "Riquelme"
                }
            ],
            "firstpage": "590",
            "lastpage": "594",
            "pub_year": 2002,
            "title": "An evolutionary algorithm to discover numeric association rules"
        },
        "b15": {
            "authors": [
                {
                    "first": "Bilal",
                    "initial": "B.",
                    "last": "Alata\u015f"
                },
                {
                    "first": "Erhan",
                    "initial": "E.",
                    "last": "Akin"
                }
            ],
            "doi": "10.1007/s00500-005-0476-x",
            "firstpage": "230",
            "issn": "14327643",
            "lastpage": "237",
            "pub_year": 2006,
            "title": "An efficient genetic algorithm for automated mining of both positive and negative quantitative association rules",
            "volume": "10"
        },
        "b16": {
            "authors": [
                {
                    "first": "Bilal",
                    "initial": "B.",
                    "last": "Alatas"
                },
                {
                    "first": "Erhan",
                    "initial": "E.",
                    "last": "Akin"
                },
                {
                    "first": "Ali",
                    "initial": "A.",
                    "last": "Karci"
                }
            ],
            "doi": "10.1016/j.asoc.2007.05.003",
            "firstpage": "646",
            "issn": "15684946",
            "lastpage": "656",
            "pub_year": 2008,
            "title": "MODENAR: Multi-objective differential evolution algorithm for mining numeric association rules",
            "volume": "8"
        },
        "b17": {
            "authors": [
                {
                    "first": "Umit",
                    "initial": "U.",
                    "last": "Can"
                },
                {
                    "first": "Bilal",
                    "initial": "B.",
                    "last": "Alatas"
                }
            ],
            "doi": "10.1142/S0218194017500127",
            "firstpage": "343",
            "issn": "02181940",
            "lastpage": "372",
            "pub_year": 2017,
            "title": "Automatic Mining of Quantitative Association Rules with Gravitational Search Algorithm",
            "volume": "27"
        },
        "b18": {
            "authors": [
                {
                    "first": "Achilleas",
                    "initial": "A.",
                    "last": "Tziatzios"
                },
                {
                    "first": "Jianhua",
                    "initial": "J.",
                    "last": "Shao"
                },
                {
                    "first": "Grigorios",
                    "initial": "G.",
                    "last": "Loukides"
                }
            ],
            "doi": "10.1109/FSKD.2011.6019723",
            "firstpage": "925",
            "lastpage": "929",
            "pub_year": 2011,
            "title": "A heuristic method for deriving range-based classification rules",
            "volume": "2"
        },
        "b19": {
            "authors": [
                {
                    "first": "Jon",
                    "initial": "J.",
                    "last": "Bentley"
                }
            ],
            "doi": "10.1145/358234.381162",
            "firstpage": "865",
            "issn": "00010782",
            "lastpage": "873",
            "pub_year": 1984,
            "title": "Programming pearls: Algorithm design techniques",
            "volume": "27"
        },
        "b2": {
            "authors": [
                {
                    "first": "Yonatan",
                    "initial": "Y.",
                    "last": "Aumann"
                },
                {
                    "first": "Yehuda",
                    "initial": "Y.",
                    "last": "Lindell"
                }
            ],
            "doi": "10.1023/A:1022812808206",
            "firstpage": "255",
            "issn": "09259902",
            "lastpage": "283",
            "pub_year": 2003,
            "title": "A statistical theory for quantitative association rules",
            "volume": "20"
        },
        "b20": {
            "authors": [
                {
                    "first": "F. A.",
                    "initial": "F.A.",
                    "last": "Thabtah"
                },
                {
                    "first": "P. I.",
                    "initial": "P.I.",
                    "last": "Cowling"
                }
            ],
            "doi": "10.1016/j.asoc.2006.10.008",
            "firstpage": "1102",
            "issn": "15684946",
            "lastpage": "1111",
            "pub_year": 2007,
            "title": "A greedy classification algorithm based on association rule",
            "volume": "7"
        },
        "b3": {
            "authors": [
                {
                    "first": "Ramakrishnan",
                    "initial": "R.",
                    "last": "Srikant"
                },
                {
                    "first": "Rakesh",
                    "initial": "R.",
                    "last": "Agrawal"
                }
            ],
            "doi": "10.1145/235968.233311",
            "firstpage": "1",
            "issn": "01635808",
            "lastpage": "12",
            "pub_year": 1996,
            "title": "Mining Quantitative Association Rules in Large Relational Tables",
            "volume": "25"
        },
        "b4": {
            "authors": [
                {
                    "first": "Takeshi",
                    "initial": "T.",
                    "last": "Fukuda"
                },
                {
                    "first": "Yasuhiko",
                    "initial": "Y.",
                    "last": "Morimoto"
                },
                {
                    "first": "Shinichi",
                    "initial": "S.",
                    "last": "Morishita"
                },
                {
                    "first": "Takeshi",
                    "initial": "T.",
                    "last": "Tokuyama"
                }
            ],
            "doi": "10.1145/383891.383893",
            "firstpage": "179",
            "issn": "03625915",
            "lastpage": "213",
            "pub_year": 2001,
            "title": "Data Mining with Optimized Two-Dimensional Association Rules",
            "volume": "26"
        },
        "b5": {
            "authors": [
                {
                    "first": "Ansaf",
                    "initial": "A.",
                    "last": "Salleb-Aouissi"
                },
                {
                    "first": "Christel",
                    "initial": "C.",
                    "last": "Vrain"
                },
                {
                    "first": "Cyril",
                    "initial": "C.",
                    "last": "Nortet"
                }
            ],
            "firstpage": "1035",
            "issn": "10450823",
            "lastpage": "1040",
            "pub_year": 2007,
            "title": "QuantMiner: A genetic algorithm for mining quantitative association rules"
        },
        "b6": null,
        "b7": {
            "authors": [
                {
                    "first": "Takeshi",
                    "initial": "T.",
                    "last": "Fukuda"
                },
                {
                    "first": "Yasuhiko",
                    "initial": "Y.",
                    "last": "Morimoto"
                },
                {
                    "first": "Shinichi",
                    "initial": "S.",
                    "last": "Morishita"
                },
                {
                    "first": "Takeshi",
                    "initial": "T.",
                    "last": "Tokuyama"
                }
            ],
            "firstpage": "182",
            "lastpage": "191",
            "pub_year": 1996,
            "title": "Mining optimized association rules for numeric attributes"
        },
        "b8": null,
        "b9": null
    },
    "body_text": [
        {
            "endOffset": 83384,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "In this section, we consider returning multiple rules from a split tree.",
            "startOffset": 83312,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 83963,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "These rules can lead to a bias, for example, when a majority vote is used to classify data using the derived rules, as a \u201cstrong\u201d rule may contain many sub-rules.",
            "startOffset": 83801,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 83311,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "The previous two strategies attempt to find one optimal rule to return, which either has the highest confidence (hence likely to be reliable) or has the largest gain (hence likely to be most characteristic) in the split tree.",
            "startOffset": 83086,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 86939,
            "parents": [],
            "secId": "sec6",
            "sentence": "In this section we report experimental results.",
            "startOffset": 86892,
            "title": "Experimental results"
        },
        {
            "endOffset": 103031,
            "parents": [],
            "secId": "sec8",
            "sentence": "While it is possible to simply use additional categorical attributes to filter out some ranges and rules discovered by our method, it will be interesting to study if such categorical attributes can be used as an integral part of sub-range derivation.",
            "startOffset": 102781,
            "title": "Conclusions"
        },
        {
            "endOffset": 60630,
            "parents": [],
            "secId": "sec1",
            "sentence": "The extraction of ranges from numerical data has also been considered in association rule mining.",
            "startOffset": 60533,
            "title": "Introduction"
        },
        {
            "endOffset": 65663,
            "parents": [],
            "secId": "sec1",
            "sentence": "Section 5 discusses experimental results and related work is analyzed in Section 6.",
            "startOffset": 65580,
            "title": "Introduction"
        },
        {
            "endOffset": 95658,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "This is because J48 mines rules by performing point-based split, and in every experiment performed this resulted in rules with large ranges and a reduced density.",
            "startOffset": 95496,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 88076,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "refoffsets": {
                "b10": {
                    "endOffset": 88010,
                    "startOffset": 88006
                }
            },
            "secId": "sec6.2",
            "sentence": "We first compare the classification accuracy of our methods to that of the Weka implementation of RIPPER algorithm and C4.5 [10] and then report the effect of density on classification accuracy.",
            "startOffset": 87882,
            "title": "Classification experiments"
        },
        {
            "endOffset": 102159,
            "parents": [],
            "secId": "sec8",
            "sentence": "This allows effectively multiple models to be discovered from data, and to be used as a type of ensemble model for classification and characterization.",
            "startOffset": 102008,
            "title": "Conclusions"
        },
        {
            "endOffset": 85651,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "Our final heuristic mirrors AllSupp, except that instead of using Min-NCI, we use Max-NCI to split a range, and instead of returning one rule from each branch that has the highest support, we return all rules that have sufficient confidence.",
            "startOffset": 85410,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 89693,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.1",
            "sentence": "As can be seen, our methods are comparable to JRip and J48 in terms of average classification accuracy with AllConf and MaxGain outperformed JRip and J48 on 6 of the 10 datasets.",
            "startOffset": 89515,
            "title": "Classification accuracy"
        },
        {
            "endOffset": 102351,
            "parents": [],
            "secId": "sec8",
            "sentence": "Our experimental results have shown that the new method is promising, and it outperformed popular rule mining methods such as C4.5 and RIPPLE in both data classification and characterization.",
            "startOffset": 102160,
            "title": "Conclusions"
        },
        {
            "endOffset": 102780,
            "parents": [],
            "secId": "sec8",
            "sentence": "Second, extending our approach to mining rules from both numerical and categorical attributes can be considered.",
            "startOffset": 102668,
            "title": "Conclusions"
        },
        {
            "endOffset": 69991,
            "parents": [],
            "secId": "sec3",
            "sentence": "To derive range-based rules, we first introduce the concept of consequent bounded ranges, and then discuss how they may be obtained from data using an apriori type of association formation.",
            "startOffset": 69802,
            "title": "Deriving associated ranges"
        },
        {
            "endOffset": 65307,
            "parents": [],
            "secId": "sec1",
            "sentence": "Our experiments show that our method is able to derive range-based rules that can offer not only good classification results, but also good characterization for numerical data.",
            "startOffset": 65131,
            "title": "Introduction"
        },
        {
            "endOffset": 67242,
            "parents": [],
            "secId": "sec2",
            "sentence": "Support",
            "startOffset": 67235,
            "title": "Preliminaries"
        },
        {
            "endOffset": 67428,
            "parents": [],
            "secId": "sec2",
            "sentence": "Confidence",
            "startOffset": 67418,
            "title": "Preliminaries"
        },
        {
            "endOffset": 98036,
            "parents": [],
            "secId": "sec7",
            "sentence": "This allows more ranges to be explored during mining, resulting in more credible rules to be found.",
            "startOffset": 97937,
            "title": "Related work"
        },
        {
            "endOffset": 91774,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "That is, their classification performance does not vary significantly when the density is set high enough.",
            "startOffset": 91668,
            "title": "Effect of density"
        },
        {
            "endOffset": 80181,
            "parents": [],
            "secId": "sec5",
            "sentence": "In the following sections we describe four such heuristics for rule formation, each implementing the Analyze function in Algorithm 1.",
            "startOffset": 80048,
            "title": "Rule formation"
        },
        {
            "endOffset": 94649,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "These results show that our methods can result in stable solutions, which implies that they can capture key underlying patterns in data, hence a good solution for data characterization.",
            "startOffset": 94464,
            "title": "Rule stability"
        },
        {
            "endOffset": 83800,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "This is, however, not desirable as we may return some rules that are contained or subsumed by other rules.",
            "startOffset": 83694,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 65699,
            "parents": [],
            "secId": "sec1",
            "sentence": "We conclude the paper in Section 7.",
            "startOffset": 65664,
            "title": "Introduction"
        },
        {
            "endOffset": 80525,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.1",
            "sentence": "This requires a simple tracking of the rule in the splitting process that has the required minimum density and the highest confidence.",
            "startOffset": 80391,
            "title": "Maximum confidence rule (MaxConf)"
        },
        {
            "endOffset": 92238,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.3",
            "sentence": "In contrast, the task of data characterization and how the effectiveness of different rule sets may be compared for their data characterization power are less clear.",
            "startOffset": 92073,
            "title": "Characterization experiments"
        },
        {
            "endOffset": 100901,
            "parents": [],
            "secId": "sec7",
            "sentence": "All range mining methods we discussed above are done in the context of either classification or association rule mining.",
            "startOffset": 100781,
            "title": "Related work"
        },
        {
            "endOffset": 65579,
            "parents": [],
            "secId": "sec1",
            "sentence": "The top-down range partitioning and a number of heuristics for rule formation are given in Section 4.",
            "startOffset": 65478,
            "title": "Introduction"
        },
        {
            "endOffset": 71712,
            "parents": [
                {
                    "id": "sec3",
                    "title": "Deriving associated ranges"
                }
            ],
            "secId": "sec3.1",
            "sentence": "c-boundaries",
            "startOffset": 71700,
            "title": "Consequent bounded ranges"
        },
        {
            "endOffset": 96417,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "We attribute this to the fact that the CARM methodology was used.",
            "startOffset": 96352,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 96351,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "Overall, our experiments show that the proposed methods offer better data characterization than the existing rule mining methods.",
            "startOffset": 96222,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 84339,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "Clearly, each branch of the split tree will form containment relation from the root to the leaf.",
            "startOffset": 84243,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 84565,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "Our AllSupp heuristic is to return one rule per branch whose support is as high as possible, as long as they have minimum confidence and density.",
            "startOffset": 84420,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 92072,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.3",
            "sentence": "The task of classification is well understood.",
            "startOffset": 92026,
            "title": "Characterization experiments"
        },
        {
            "endOffset": 97092,
            "parents": [],
            "refoffsets": {
                "b11": {
                    "endOffset": 97091,
                    "startOffset": 97087
                }
            },
            "secId": "sec7",
            "sentence": "One popular approach to obtaining ranges from numerical attributes is discretization and many techniques have been proposed to discretize numerical data as a pre-processing step in rule mining [11].",
            "startOffset": 96894,
            "title": "Related work"
        },
        {
            "endOffset": 91568,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "The experiments results seem to suggest that such dangling cases would do little harm, and finding appropriate boundaries for the ranges involved in a rule has a more significant impact on classification accuracy.",
            "startOffset": 91355,
            "title": "Effect of density"
        },
        {
            "endOffset": 97936,
            "parents": [],
            "secId": "sec7",
            "sentence": "Our method can also be broadly considered as discretization, except that we perform a top-down split as opposed to a bottom-up merge, and we perform this directly in the rule mining process without a pre-processing step.",
            "startOffset": 97716,
            "title": "Related work"
        },
        {
            "endOffset": 86064,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "Rule Redundancy",
            "startOffset": 86049,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 91667,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "We can however observe that large density seemed to produce more stable classification performance.",
            "startOffset": 91568,
            "title": "Effect of density"
        },
        {
            "endOffset": 59925,
            "parents": [],
            "refoffsets": {
                "b1": {
                    "endOffset": 59924,
                    "startOffset": 59921
                }
            },
            "secId": "sec1",
            "sentence": "Existing methods typically follow a \u201ccover and remove\u201d strategy [1].",
            "startOffset": 59857,
            "title": "Introduction"
        },
        {
            "endOffset": 102407,
            "parents": [],
            "secId": "sec8",
            "sentence": "There are two issues to be addressed in future research.",
            "startOffset": 102351,
            "title": "Conclusions"
        },
        {
            "endOffset": 83566,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "This is useful when the dataset contains multiple, perhaps even conflicting knowledge patterns, and returning just one rule may be too limited, especially for data characterization.",
            "startOffset": 83385,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 91049,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "Close examination of the experimental results showed that high density settings resulted in many narrow ranges, and these ranges seemed to have caused some overfitting.",
            "startOffset": 90881,
            "title": "Effect of density"
        },
        {
            "endOffset": 85248,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "Hence this rule is returned.",
            "startOffset": 85220,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 90817,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "We observed that increasing the density threshold reduced the number of rules generated, and overall this has also led to the drop in classification accuracy.",
            "startOffset": 90659,
            "title": "Effect of density"
        },
        {
            "endOffset": 93312,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "If the difference is small, then we consider our characterization of the data is stable, as adding 10% data to the dataset has not significantly changed the model derived from the data.",
            "startOffset": 93127,
            "title": "Rule stability"
        },
        {
            "endOffset": 61169,
            "parents": [],
            "refoffsets": {
                "b2": {
                    "endOffset": 61056,
                    "startOffset": 61053
                },
                "b3": {
                    "endOffset": 60792,
                    "startOffset": 60789
                },
                "b4": {
                    "endOffset": 60930,
                    "startOffset": 60927
                },
                "b5": {
                    "endOffset": 61168,
                    "startOffset": 61165
                }
            },
            "secId": "sec1",
            "sentence": "For example, Srikant and Agrawal proposed a method that partitions numerical data into initial ranges first and then allows neighboring ranges to be combined [3]; Fukuda et al. developed an efficient method that allows rectangular regions to be found from two dimensional numerical data directly [4]; Autmann and Lindell suggested a statistical model which focuses on discovering ranges that are statistically significant [2]; and Salleb-Aouissi et al. used genetic algorithms to derive ranges heuristically from numerical attributes [5].",
            "startOffset": 60631,
            "title": "Introduction"
        },
        {
            "endOffset": 91995,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "As such, they tend to be more reliable when used to classify unseen cases.",
            "startOffset": 91921,
            "title": "Effect of density"
        },
        {
            "endOffset": 89406,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.1",
            "sentence": "Table 5 shows a summary of the average classification accuracy (over different training datasets) achieved in the experiments.",
            "startOffset": 89280,
            "title": "Classification accuracy"
        },
        {
            "endOffset": 59856,
            "parents": [],
            "secId": "sec1",
            "sentence": "Extracting ranges from numerical attributes has been considered in classification rule mining.",
            "startOffset": 59762,
            "title": "Introduction"
        },
        {
            "endOffset": 60421,
            "parents": [],
            "secId": "sec1",
            "sentence": "Consequently, these methods resort to discretization or point-based split.",
            "startOffset": 60347,
            "title": "Introduction"
        },
        {
            "endOffset": 85718,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "The method is similar to Algorithm 4, and is shown in Algorithm 5.",
            "startOffset": 85652,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 95405,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "In all cases 100% of datasets were used to mine the rules.",
            "startOffset": 95347,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 83983,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "Subrule",
            "startOffset": 83976,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 69336,
            "parents": [],
            "secId": "sec2",
            "sentence": "Min-\u03c3\u03b3\u03b4 Rule",
            "startOffset": 69324,
            "title": "Preliminaries"
        },
        {
            "endOffset": 90880,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "This is an interesting finding and is against our expectation.",
            "startOffset": 90818,
            "title": "Effect of density"
        },
        {
            "endOffset": 91920,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "This is largely expected as when the density is high, the discovered associated ranges would contain many actually observed cases in the dataset.",
            "startOffset": 91775,
            "title": "Effect of density"
        },
        {
            "endOffset": 97609,
            "parents": [],
            "refoffsets": {
                "b3": {
                    "endOffset": 97608,
                    "startOffset": 97605
                }
            },
            "secId": "sec7",
            "sentence": "For example, Srikant and Agrawal proposed to use equi-depth partitioning to group individual data items into initial ranges first, and then allow neighboring ranges to be combined based on a user specified threshold [3].",
            "startOffset": 97389,
            "title": "Related work"
        },
        {
            "endOffset": 101882,
            "parents": [],
            "secId": "sec8",
            "sentence": "Our method is inspired by the CARM approach: we search for associated ranges in a similar way to how associated items are searched for in conventional association rule mining, but we guide the range search with class values.",
            "startOffset": 101658,
            "title": "Conclusions"
        },
        {
            "endOffset": 60142,
            "parents": [],
            "secId": "sec1",
            "sentence": "This is repeated on the remaining data until all the data is covered this way.",
            "startOffset": 60064,
            "title": "Introduction"
        },
        {
            "endOffset": 93919,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "For conciseness of presentation, we only report the experimental results on three datasets here: the Ecoli and Glass datasets represent the cases where prediction using our methods is less and more accurate than the other two methods, respectively, whereas the Breast Cancer dataset is used as a representative case, where the average of classification accuracy by our methods outperformed the other two.",
            "startOffset": 93515,
            "title": "Rule stability"
        },
        {
            "endOffset": 81564,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.2",
            "sentence": "This may not be desirable as, for example, very confident rules may represent some known knowledge.",
            "startOffset": 81465,
            "title": "Maximum gain rule (MaxGain)"
        },
        {
            "endOffset": 93126,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "That is, we measure the difference in classification accuracy when the amount of training data is changed from, say 50% to 60% or 60% to 70%.",
            "startOffset": 92985,
            "title": "Rule stability"
        },
        {
            "endOffset": 85219,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "This is because any sub-rule obtained from this point on (i.e. any rules at a lower node in the split tree) will be contained in this rule as sub-rules and these sub-rules cannot have a higher support than the current rule due to the monotonic property.",
            "startOffset": 84966,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 92984,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "Fig. 5 shows a comparison of differences in classification accuracy when changing the percentage of data used for training.",
            "startOffset": 92861,
            "title": "Rule stability"
        },
        {
            "endOffset": 101135,
            "parents": [],
            "refoffsets": {
                "b6": {
                    "endOffset": 101134,
                    "startOffset": 101131
                }
            },
            "secId": "sec7",
            "sentence": "In contrast, our work adopts the CARM methodology [6].",
            "startOffset": 101081,
            "title": "Related work"
        },
        {
            "endOffset": 87741,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.1",
            "sentence": "Table 4 contains a summary of the characteristics of each dataset.",
            "startOffset": 87675,
            "title": "Experments setup"
        },
        {
            "endOffset": 96222,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "Together with our analysis of density on classification accuracy in Section 6.2.2, this suggests that highly confident rules are better for classification whereas highly supported rules are better for data characterization.",
            "startOffset": 95999,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 84696,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "The method is described in Algorithm 4, which returns a set of rules from a split tree that do not have containment relationships.",
            "startOffset": 84566,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 96881,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "This is important to the derivation of stable, comprehensible characterization models from data.",
            "startOffset": 96785,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 101412,
            "parents": [],
            "refoffsets": {
                "b20": {
                    "endOffset": 101411,
                    "startOffset": 101407
                }
            },
            "secId": "sec7",
            "sentence": "While some methods have been proposed to mine rules using CARM, they are restricted to deal with categorical data only [20].",
            "startOffset": 101288,
            "title": "Related work"
        },
        {
            "endOffset": 65130,
            "parents": [],
            "secId": "sec1",
            "sentence": "To the best of our knowledge our proposed method is the only one that is able to derive associated ranges from any number of numerical attributes through a top-down range split, and to build an ensemble type of range-based rule set for classification as well as characterization.",
            "startOffset": 64851,
            "title": "Introduction"
        },
        {
            "endOffset": 81682,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.2",
            "sentence": "In this section, we consider how we might strike a balance between support and confidence, and optimize both jointly.",
            "startOffset": 81565,
            "title": "Maximum gain rule (MaxGain)"
        },
        {
            "endOffset": 80047,
            "parents": [],
            "secId": "sec5",
            "sentence": "Different strategies may be used to form rules by selecting certain sub-ranges from the split tree.",
            "startOffset": 79948,
            "title": "Rule formation"
        },
        {
            "endOffset": 76496,
            "parents": [],
            "secId": "sec4",
            "sentence": "Non-consequent Interval",
            "startOffset": 76473,
            "title": "Range analysis"
        },
        {
            "endOffset": 102667,
            "parents": [],
            "refoffsets": {
                "b2": {
                    "endOffset": 102609,
                    "startOffset": 102606
                }
            },
            "secId": "sec8",
            "sentence": "First, it is worth considering how rules with ranges in the consequent may be mined using the proposed approach, for example, discovering ranges in the consequent that are statistically significant [2] and use them to guide the formation of range-based rules.",
            "startOffset": 102408,
            "title": "Conclusions"
        },
        {
            "endOffset": 85789,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "Again we only show the steps that are different from Algorithm 4 here.",
            "startOffset": 85719,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 97388,
            "parents": [],
            "secId": "sec7",
            "sentence": "Some range merging techniques have also been considered during rule mining to refine the initial ranges obtained from discretization.",
            "startOffset": 97255,
            "title": "Related work"
        },
        {
            "endOffset": 66630,
            "parents": [],
            "secId": "sec2",
            "sentence": "Associated Ranges",
            "startOffset": 66613,
            "title": "Preliminaries"
        },
        {
            "endOffset": 101080,
            "parents": [],
            "secId": "sec7",
            "sentence": "That is, they look for best ways of partitioning numerical data and deriving rules from such partitioning.",
            "startOffset": 100974,
            "title": "Related work"
        },
        {
            "endOffset": 60063,
            "parents": [],
            "secId": "sec1",
            "sentence": "That is, a rule is heuristically formed to cover a subset of the data as well as possible, and this subset is then removed from the data.",
            "startOffset": 59926,
            "title": "Introduction"
        },
        {
            "endOffset": 65427,
            "parents": [],
            "secId": "sec1",
            "sentence": "In Section 2, we give the necessary definitions that we use in the paper.",
            "startOffset": 65354,
            "title": "Introduction"
        },
        {
            "endOffset": 69312,
            "parents": [],
            "secId": "sec2",
            "sentence": "One class of rules of interest is those whose support, confidence and density are above a minimum threshold.",
            "startOffset": 69204,
            "title": "Preliminaries"
        },
        {
            "endOffset": 91354,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "Our density measure is a conservative assessment that treats dangling cases as those that are likely to lead to wrong predictions.",
            "startOffset": 91224,
            "title": "Effect of density"
        },
        {
            "endOffset": 102007,
            "parents": [],
            "secId": "sec8",
            "sentence": "To do so, we have introduced a number of heuristics for splitting ranges into sub-ranges and for range-based rule formation.",
            "startOffset": 101883,
            "title": "Conclusions"
        },
        {
            "endOffset": 87333,
            "parents": [],
            "secId": "sec6",
            "sentence": "We compare our methods to C4.5 and RIPPER because these two methods are widely used and studied, and they produce human-interpretable rules as we do in our work.",
            "startOffset": 87172,
            "title": "Experimental results"
        },
        {
            "endOffset": 89824,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.1",
            "sentence": "It is also worth mentioning that the proposed methods are designed to achieve good data characterization as well as classification.",
            "startOffset": 89693,
            "title": "Classification accuracy"
        },
        {
            "endOffset": 92787,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "That is, if adding a small percentage of cases to a dataset does not change the resulting rules significantly, then a set of rules derived from data can be considered as having truly characterized data, since the key data characteristics should not have changed significantly when the data is slightly varied.",
            "startOffset": 92478,
            "title": "Rule stability"
        },
        {
            "endOffset": 66276,
            "parents": [],
            "secId": "sec2",
            "sentence": "Range",
            "startOffset": 66271,
            "title": "Preliminaries"
        },
        {
            "endOffset": 87087,
            "parents": [],
            "secId": "sec6",
            "sentence": "We compare the proposed methods to C4.5 and RIPPER in terms of their classification accuracy and their ability to characterize a given set of data.",
            "startOffset": 86940,
            "title": "Experimental results"
        },
        {
            "endOffset": 90098,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.1",
            "sentence": "While these experiments confirm that the new methods are able to achieve classification performance that is broadly comparable to two of the most popular rule mining solutions, they can achieve a superior performance in data characterization, as we will see in Section 6.3.",
            "startOffset": 89825,
            "title": "Classification accuracy"
        },
        {
            "endOffset": 92861,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "We therefore use stability as a measure of data characterization quality.",
            "startOffset": 92788,
            "title": "Rule stability"
        },
        {
            "endOffset": 103083,
            "parents": [],
            "secId": "sec8",
            "sentence": "We plan to address these issues in our future work.",
            "startOffset": 103032,
            "title": "Conclusions"
        },
        {
            "endOffset": 87438,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "refoffsets": {
                "b9": {
                    "endOffset": 87409,
                    "startOffset": 87406
                }
            },
            "secId": "sec6.1",
            "sentence": "A number of datasets selected from the UCI repository [9] are used in the experiments.",
            "startOffset": 87352,
            "title": "Experments setup"
        },
        {
            "endOffset": 94198,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "We attribute this to the fact that CARM was used, and we are able to take inconsistent patterns within the data into account, producing more robust results.",
            "startOffset": 94042,
            "title": "Rule stability"
        },
        {
            "endOffset": 93514,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "We compare our MaxGain and AllConf methods to JRip and J48 as AllConf gives best classification accuracy in our study and MaxGain is the only one that attempts to balance between support and confidence.",
            "startOffset": 93312,
            "title": "Rule stability"
        },
        {
            "endOffset": 95495,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "As we can see, J48 is completely outperformed by the other solutions in every single case.",
            "startOffset": 95405,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 100973,
            "parents": [],
            "secId": "sec7",
            "sentence": "In so doing they attempt to discover a single, optimal model from data.",
            "startOffset": 100902,
            "title": "Related work"
        },
        {
            "endOffset": 97254,
            "parents": [],
            "secId": "sec7",
            "sentence": "These methods rely on the discretization criteria used and there is no guarantee that relevant or optimal ranges will be captured during the pre-processing step.",
            "startOffset": 97093,
            "title": "Related work"
        },
        {
            "endOffset": 83693,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "One obvious approach is to create the full tree and then return every internal node that has sufficient confidence and density.",
            "startOffset": 83566,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 101287,
            "parents": [],
            "secId": "sec7",
            "sentence": "This allows effectively multiple models to be discovered from data, and to be used as a type of ensemble model for classification and characterization.",
            "startOffset": 101136,
            "title": "Related work"
        },
        {
            "endOffset": 92346,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.3",
            "sentence": "In this section we introduce two measures to study the data characterization power of our proposed methods.",
            "startOffset": 92239,
            "title": "Characterization experiments"
        },
        {
            "endOffset": 95308,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "In this set of experiments, we selected the 10 most confident and 10 most supported rules for each dataset and measured their median density.",
            "startOffset": 95167,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 101657,
            "parents": [],
            "secId": "sec8",
            "sentence": "In this paper, we proposed a method for finding range-based rules from numerical data in order to build classification and characterization models.",
            "startOffset": 101510,
            "title": "Conclusions"
        },
        {
            "endOffset": 65477,
            "parents": [],
            "secId": "sec1",
            "sentence": "In Section 3, we introduce our CARM-based method.",
            "startOffset": 65428,
            "title": "Introduction"
        },
        {
            "endOffset": 96633,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "Rather than following the cover and remove strategy, aiming to derive a single optimal model from the data, we allow many credible rules to be discovered and used collectively in classification and characterization.",
            "startOffset": 96418,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 80390,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.1",
            "sentence": "We call this strategy maximum confidence rule (MaxConf).",
            "startOffset": 80334,
            "title": "Maximum confidence rule (MaxConf)"
        },
        {
            "endOffset": 81728,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "refoffsets": {
                "b4": {
                    "endOffset": 81727,
                    "startOffset": 81724
                }
            },
            "secId": "sec5.2",
            "sentence": "To achieve this, we use the gain measure [4].",
            "startOffset": 81683,
            "title": "Maximum gain rule (MaxGain)"
        },
        {
            "endOffset": 87881,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.2",
            "sentence": "This section presents the results of experiments on the performance of the proposed methods for classification.",
            "startOffset": 87770,
            "title": "Classification experiments"
        },
        {
            "endOffset": 84868,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "The split of rule stops as soon as a rule is found with minimum support, confidence and density (step 4\u20136).",
            "startOffset": 84761,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 86036,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "That is, these rules have their confidence lower than their ancestors.",
            "startOffset": 85966,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 95822,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "AllConf performed better than MaxGain due to its rule formation heuristic: most confident rules tend to cover relatively fewer tuples, resulting in higher density.",
            "startOffset": 95659,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 80592,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.1",
            "sentence": "Note that all the rules in the split tree have sufficient support.",
            "startOffset": 80526,
            "title": "Maximum confidence rule (MaxConf)"
        },
        {
            "endOffset": 94344,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "It is also interesting to observe that when the percentage of training data change from 80 to 90, the MaxGain method performed consistently well.",
            "startOffset": 94199,
            "title": "Rule stability"
        },
        {
            "endOffset": 95346,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "The results are presented in Table 6.",
            "startOffset": 95309,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 96784,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "Consequently, a small change in data might affect the accuracy of some isolated rules that were learnt, but it would not affect the overall discovery.",
            "startOffset": 96634,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 81464,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.2",
            "sentence": "The maximum confidence rule strategy can sacrifice substantial support for confidence.",
            "startOffset": 81378,
            "title": "Maximum gain rule (MaxGain)"
        },
        {
            "endOffset": 89514,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.1",
            "sentence": "The AllSupp method is omitted here, as its classification accuracy was not comparable to the other methods.",
            "startOffset": 89407,
            "title": "Classification accuracy"
        },
        {
            "endOffset": 84419,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "That is, each rule at a node is contained in the rule at its predecessor nodes.",
            "startOffset": 84340,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 84965,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "We will only split a rule that has enough support but not enough confidence or density (step 8).",
            "startOffset": 84869,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 97715,
            "parents": [],
            "secId": "sec7",
            "sentence": "Wang et al. proposed a clustering based method which successively merges neighboring values into a range.",
            "startOffset": 97610,
            "title": "Related work"
        },
        {
            "endOffset": 66448,
            "parents": [],
            "secId": "sec2",
            "sentence": "Cover",
            "startOffset": 66443,
            "title": "Preliminaries"
        },
        {
            "endOffset": 91223,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.2",
                    "title": "Classification experiments"
                }
            ],
            "secId": "sec6.2.2",
            "sentence": "Our results therefore suggest that the boundaries and association of ranges are more important than how many values are actually observed to be associated across the ranges.",
            "startOffset": 91050,
            "title": "Effect of density"
        },
        {
            "endOffset": 61430,
            "parents": [],
            "secId": "sec1",
            "sentence": "All these methods aim to derive ranges with some kind of optimality, but they are either limited to dealing with no more than two numerical attributes or they do not attempt to find range-based rules that can support classification as well as characterization.",
            "startOffset": 61170,
            "title": "Introduction"
        },
        {
            "endOffset": 94041,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "The figures demonstrate that both AllConf and MaxGain methods performed more consistently than JRip and J48 in most cases.",
            "startOffset": 93919,
            "title": "Rule stability"
        },
        {
            "endOffset": 85965,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "Note that some of the rules passing steps 4\u20135 are redundant.",
            "startOffset": 85905,
            "title": "All confident rules (AllConf)"
        },
        {
            "endOffset": 87171,
            "parents": [],
            "secId": "sec6",
            "sentence": "We also examine the effect of our density measure on the quality of rule induction.",
            "startOffset": 87088,
            "title": "Experimental results"
        },
        {
            "endOffset": 60346,
            "parents": [],
            "secId": "sec1",
            "sentence": "This strategy works well with categorical data, but is not effective when dealing with numerical attributes, because there is a potentially very large number of ways to form ranges and to cover the data.",
            "startOffset": 60143,
            "title": "Introduction"
        },
        {
            "endOffset": 80333,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.1",
            "sentence": "We first describe a strategy which returns a single rule from the splitting process that has the highest confidence.",
            "startOffset": 80217,
            "title": "Maximum confidence rule (MaxConf)"
        },
        {
            "endOffset": 84760,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "The methods is similar to Algorithm 2 with one main difference.",
            "startOffset": 84697,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 95998,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.2",
            "sentence": "Comparing the two sets of results, it is useful to observe that for all methods selecting the rules with most support results in better density than the most confidence rules.",
            "startOffset": 95823,
            "title": "Top k rule cohesion"
        },
        {
            "endOffset": 87674,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                }
            ],
            "secId": "sec6.1",
            "sentence": "These datasets are among the most popular datasets used in the research community for studying classification and they vary in tuple and attribute size, the nature of their numerical attributes and the number of different class labels.",
            "startOffset": 87439,
            "title": "Experments setup"
        },
        {
            "endOffset": 65353,
            "parents": [],
            "secId": "sec1",
            "sentence": "The rest of the paper is organized as follows.",
            "startOffset": 65307,
            "title": "Introduction"
        },
        {
            "endOffset": 94463,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "Thus, it appears that in characterizing data, seeking balance between support and confidence is an effective strategy.",
            "startOffset": 94345,
            "title": "Rule stability"
        },
        {
            "endOffset": 101498,
            "parents": [],
            "secId": "sec7",
            "sentence": "We, on the other hand, extend the approach to deal with numerical data in this paper.",
            "startOffset": 101413,
            "title": "Related work"
        },
        {
            "endOffset": 85378,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.3",
            "sentence": "In order to maximize support, we use Min-NCI to split a range, thereby retaining as much support as possible following the split.",
            "startOffset": 85249,
            "title": "All supported rules (AllSupp)"
        },
        {
            "endOffset": 81745,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.2",
            "sentence": "Gain",
            "startOffset": 81741,
            "title": "Maximum gain rule (MaxGain)"
        },
        {
            "endOffset": 66836,
            "parents": [],
            "secId": "sec2",
            "sentence": "Range-based Classification Rule",
            "startOffset": 66805,
            "title": "Preliminaries"
        },
        {
            "endOffset": 92477,
            "parents": [
                {
                    "id": "sec6",
                    "title": "Experimental results"
                },
                {
                    "id": "sec6.3",
                    "title": "Characterization experiments"
                }
            ],
            "secId": "sec6.3.1",
            "sentence": "If discovered rules are relatively stable, then we may consider that the rules have characterized the data well.",
            "startOffset": 92365,
            "title": "Rule stability"
        },
        {
            "endOffset": 60533,
            "parents": [],
            "refoffsets": {
                "b2": {
                    "endOffset": 60532,
                    "startOffset": 60529
                }
            },
            "secId": "sec1",
            "sentence": "However, these mechanisms may not capture some relevant ranges and do not help understand discovered rules [2].",
            "startOffset": 60422,
            "title": "Introduction"
        },
        {
            "endOffset": 67667,
            "parents": [],
            "secId": "sec2",
            "sentence": "Density",
            "startOffset": 67660,
            "title": "Preliminaries"
        },
        {
            "endOffset": 85904,
            "parents": [
                {
                    "id": "sec5",
                    "title": "Rule formation"
                }
            ],
            "secId": "sec5.4",
            "sentence": "As confidence is not monotonic, we need to continue splitting the ranges until they no longer have enough support.",
            "startOffset": 85790,
            "title": "All confident rules (AllConf)"
        }
    ],
    "docId": "S0169023X17304329",
    "metadata": {
        "asjc": [
            "1802"
        ],
        "authors": [
            {
                "email": "ShaoJ@cardiff.ac.uk",
                "first": "Jianhua",
                "initial": "J.",
                "last": "Shao"
            },
            {
                "email": null,
                "first": "Achilleas",
                "initial": "A.",
                "last": "Tziatzios"
            }
        ],
        "doi": "10.1016/j.datak.2018.10.001",
        "firstpage": "92",
        "issn": "0169023X",
        "keywords": [
            "Characterization",
            "Classification",
            "Classification association rule mining",
            "Numerical ranges"
        ],
        "lastpage": "106",
        "openaccess": "Full",
        "pub_year": 2018,
        "subjareas": [
            "DECI"
        ],
        "title": "Mining range associations for classification and characterization"
    }
}